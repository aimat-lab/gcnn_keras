{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183317fb",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214914c-e591-4b1a-ab8a-972618784960",
   "metadata": {},
   "source": [
    "Some example data to show model inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9324d38-d5c1-4c18-a65b-d5fbba624230",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import keras as ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4447793",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409c5e0",
   "metadata": {},
   "source": [
    "Like most models in `kgcnn.literature` the models can be set up with the `keras` functional API. Here an example for a simple message passing GNN. The layers are taken from `kgcnn.layers` . See documentation of layers for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828e8089-8e98-4645-a08c-914432e79436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgcnn.layers.casting import CastRaggedIndicesToDisjoint\n",
    "from kgcnn.layers.gather import GatherNodes\n",
    "from kgcnn.layers.pooling import PoolingNodes\n",
    "from kgcnn.layers.aggr import AggregateLocalEdges\n",
    "from kgcnn.layers.modules import Input\n",
    "\n",
    "ns = Input(shape=(None, 1), dtype=\"float32\", ragged=True)\n",
    "e_idx = Input(shape=(None, 2), dtype=\"int64\", ragged=True)\n",
    "\n",
    "# Model is build with ragged input.\n",
    "n, idx, batch_id, _, _, _, total_n, total_e = CastRaggedIndicesToDisjoint()([ns, e_idx])\n",
    "n_in_out = GatherNodes()([n, idx])\n",
    "node_messages = ks.layers.Dense(64, activation='relu')(n_in_out)\n",
    "node_updates = AggregateLocalEdges()([n, node_messages, idx])\n",
    "n_node_updates = ks.layers.Concatenate()([n, node_updates])\n",
    "n_embedding = ks.layers.Dense(1)(n_node_updates)\n",
    "g_embedding = PoolingNodes()([total_n, n_embedding, batch_id])\n",
    "\n",
    "message_passing = ks.models.Model(inputs=[ns, e_idx], outputs=g_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d81b1",
   "metadata": {},
   "source": [
    "## Subclassing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe0f2f",
   "metadata": {},
   "source": [
    "A model can be constructed by subclassing from `keras.models.Model` where the call method must be implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e47986a-fc66-4736-b74f-e941a4886fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgcnn.layers.casting import CastBatchedIndicesToDisjoint\n",
    "\n",
    "class MessagePassingModel(ks.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._layer_casting = CastBatchedIndicesToDisjoint(uses_mask=False)\n",
    "        self._layer_gather_nodes = GatherNodes()\n",
    "        self._layer_dense = ks.layers.Dense(64, activation='relu')\n",
    "        self._layer_aggregate_edges = AggregateLocalEdges()\n",
    "        self._layer_cat = ks.layers.Concatenate(axis=-1)\n",
    "        self._layer_dense_last = ks.layers.Dense(1)\n",
    "        self._layer_pool_nodes = PoolingNodes()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Here we use padded input\n",
    "        # nodes, indices, total_nodes, total_edges = inputs\n",
    "        n, idx, batch_id, _, _, _, total_n, total_e = self._layer_casting(inputs)\n",
    "        n_in_out = self._layer_gather_nodes([n, idx])\n",
    "        node_messages = self._layer_dense(n_in_out)\n",
    "        node_updates = self._layer_aggregate_edges([n, node_messages, idx])\n",
    "        n_node_updates = self._layer_cat([n, node_updates])\n",
    "        n_embedding = self._layer_dense_last(n_node_updates)\n",
    "        g_embedding = self._layer_pool_nodes([total_n, n_embedding, batch_id])\n",
    "        return g_embedding\n",
    "\n",
    "message_passing_2 = MessagePassingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa190f8b-2d77-49a6-8a7d-9daa921eabee",
   "metadata": {},
   "source": [
    "## Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810da1f6",
   "metadata": {},
   "source": [
    "Also layers can be further subclassed to create a GNN, for example of the message passing base layer. Where only `message_function` and `update_nodes` must be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d831f1-6699-46fc-a62c-b4d2dbafabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgcnn.layers.message import MessagePassingBase\n",
    "\n",
    "class MyMessageNN(MessagePassingBase):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(MyMessageNN, self).__init__(**kwargs)\n",
    "        self.dense = ks.layers.Dense(units, activation='relu')\n",
    "        self.cat = ks.layers.Concatenate(axis=-1)\n",
    "\n",
    "    def message_function(self, inputs, **kwargs):\n",
    "        n_in, n_out = inputs\n",
    "        n_in_out = self.cat([n_in, n_out])\n",
    "        return self.dense(n_in_out, **kwargs)\n",
    "\n",
    "    def update_nodes(self, inputs, **kwargs):\n",
    "        nodes, nodes_update = inputs\n",
    "        return self.cat([nodes, nodes_update], **kwargs)\n",
    "\n",
    "# Here we use direct disjoint input\n",
    "n = ks.layers.Input(shape=(1, ), dtype=\"float32\")\n",
    "idx = ks.layers.Input(shape=(None, ), dtype=\"int64\")\n",
    "batch_id = ks.layers.Input(shape=(), dtype=\"int64\")\n",
    "total_n = ks.layers.Input(shape=(), dtype=\"int64\")\n",
    "\n",
    "n_node_updates = MyMessageNN(units=64)([n, idx])\n",
    "n_embedding = ks.layers.Dense(1)(n_node_updates)\n",
    "g_embedding = PoolingNodes()([total_n, n_embedding, batch_id])\n",
    "\n",
    "message_passing_3 = ks.models.Model(inputs=[n, idx, batch_id, total_n], outputs=g_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac5472",
   "metadata": {},
   "source": [
    "## Loading options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5397e58",
   "metadata": {},
   "source": [
    "There are many options to load data to a keras model, which depend on the size and location of the data to pass to the model. There may differences in speed and utility depending on the loading method. For more examples, please find https://github.com/aimat-lab/gcnn_keras/blob/master/notebooks/tutorial_model_loading_options.ipynb ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702defc-6dfe-4b96-b4f4-981e0fd16028",
   "metadata": {},
   "source": [
    "In general padded tensor is most convenient and natural to keras but comes with a significant performance drop. Ragged tensor is restricted to tensorflow as of now but will likely be extended to pytorch as well. Direct disjoint input is most efficient but requires a dataloader to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a553cf4-463b-4c29-9b34-3e7a5d748096",
   "metadata": {},
   "source": [
    "##### 1. Padded Tensor\n",
    "\n",
    "The most simple way to pass tensors to the model is to simply pad to same size tensor. For the model input further information is required on the padding. Either a length tensor or a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d32927-e70a-4160-a0cb-9d3e22066e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import ops\n",
    "example_nodes = ops.convert_to_tensor([[[1.], [2.]], [[1.0], [0.0]], [[2.0], [0.0]], [[4.0], [0.0]]])\n",
    "example_indices = ops.convert_to_tensor([[[0, 1], [1, 0], [1,1]], [[0, 0], [0, 0], [0, 0]], [[0, 0], [0, 0], [0, 0]], [[0, 0], [0, 0], [0, 0]]], dtype=\"int64\")\n",
    "example_total_nodes = ops.convert_to_tensor([2, 1, 1, 1], dtype=\"int64\")\n",
    "example_total_edges = ops.convert_to_tensor([3, 1, 1, 1], dtype=\"int64\")\n",
    "example_graph_labels = ops.convert_to_tensor([[1.0], [0.1], [0.3], [0.6]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c60580-3a2e-4eca-8eb4-d42fd6a31401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.340108  ],\n",
       "       [0.26912418],\n",
       "       [0.53824836],\n",
       "       [1.0764967 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_passing_2.predict([example_nodes, example_indices, example_total_nodes, example_total_edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957e43f2-ddf0-436b-b1b7-6101bee52f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2488  \n",
      "Epoch 2/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1036 \n",
      "Epoch 3/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0680 \n",
      "Epoch 4/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1017 \n",
      "Epoch 5/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0918 \n",
      "Epoch 6/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0945 \n",
      "Epoch 7/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0903 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2601c652dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_passing_2.compile(loss=\"mean_absolute_error\")\n",
    "message_passing_2.fit(x=[example_nodes, example_indices, example_total_nodes, example_total_edges], y=example_graph_labels, batch_size=2, epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd8bb7-40d2-4ad4-a55c-8290936dc601",
   "metadata": {},
   "source": [
    "##### 2. Ragged input\n",
    "\n",
    "More data efficient is ragged or jagged tensor input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5daf500f-1379-4d8e-ac19-69614fd64a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, None, 1) (4, None, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend import backend\n",
    "if backend() == \"tensorflow\":\n",
    "    example_nodes = tf.ragged.constant([[[1.], [2.]], [[1.0]], [[2.0]], [[4.0]]], ragged_rank=1)\n",
    "    example_indices =  tf.ragged.constant([[[0, 1], [1, 0], [1,1]], [[0, 0]], [[0, 0]], [[0, 0]]], dtype=\"int64\", ragged_rank=1)\n",
    "    print(example_nodes.shape, example_indices.shape)\n",
    "elif backend() == \"torch\":\n",
    "    # from torchrec.sparse.jagged_tensor import JaggedTensor\n",
    "    raise NotImplementedError()\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7146bee7-f332-4d69-9a11-54b97b92615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.2719753],\n",
       "       [-0.5563201],\n",
       "       [-1.1126401],\n",
       "       [-2.2252803]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_passing.predict([example_nodes, example_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19815353-4f53-4472-8005-6c317aeb4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6347  \n",
      "Epoch 2/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6999 \n",
      "Epoch 3/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6529 \n",
      "Epoch 4/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4860 \n",
      "Epoch 5/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1121 \n",
      "Epoch 6/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2790 \n",
      "Epoch 7/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1712 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2601f90ece0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_passing.compile(loss=\"mean_absolute_error\")\n",
    "message_passing.fit(x=[example_nodes, example_indices], y=example_graph_labels, batch_size=2, epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22b92c-98ee-4a41-bbec-9e0a8884409f",
   "metadata": {},
   "source": [
    "##### 3. Direct disjoint input via data loader.\n",
    "\n",
    "We need to construct a data pipeline. Fully working datapipelines will be provided in `kgcnn.io` .\n",
    "They can be either based on `tf.data` or `torch.Dataloader` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb4a414-ea57-40e4-b346-051f16ec7a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 4\n"
     ]
    }
   ],
   "source": [
    "example_nodes = [[[1.], [2.]], [[1.0]], [[2.0]], [[4.0]]]\n",
    "example_indices =  [[[0, 1], [1, 0], [1,1]], [[0, 0]], [[0, 0]],  [[0, 0]]]\n",
    "example_graph_labels = [[1.0], [0.1], [0.3], [0.6]]\n",
    "print(len(example_nodes), len(example_indices), len(example_graph_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f943b6d-9884-4754-866d-dd397ec7fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "data_length = 3\n",
    "\n",
    "# Minimal example to generate disjoint input from baisc operations.\n",
    "def gen():\n",
    "    for i in range(0, data_length, batch_size):\n",
    "        gen_nodes = tf.concat(example_nodes[i:i+batch_size], axis=0)\n",
    "        gen_total_nodes = tf.constant([len(x) for x in example_nodes[i:i+batch_size]], dtype=\"int64\")\n",
    "        gen_total_edges = tf.constant([len(x) for x in example_indices[i:i+batch_size]], dtype=\"int64\")\n",
    "        gen_batch_id = tf.repeat(tf.range(len(gen_total_nodes), dtype=\"int64\"), gen_total_nodes)\n",
    "        gen_indices = tf.cast(tf.concat(example_indices[i:i+batch_size], axis=0), dtype=\"int64\")\n",
    "        gen_node_splits = tf.pad(tf.cumsum(gen_total_nodes), [[1, 0]])\n",
    "        gen_indices_offset = tf.expand_dims(tf.repeat(gen_node_splits[:-1], gen_total_edges), axis=-1)\n",
    "        gen_indices = gen_indices + gen_indices_offset\n",
    "        gen_indices = tf.transpose(gen_indices)\n",
    "        yield (gen_nodes, gen_indices, gen_batch_id, gen_total_nodes)\n",
    "    \n",
    "ds_x_batch = tf.data.Dataset.from_generator(\n",
    "    gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=\"float32\"),\n",
    "        tf.TensorSpec(shape=(2, None), dtype=\"int64\"),\n",
    "        tf.TensorSpec(shape=(None, ), dtype=\"int64\"),\n",
    "        tf.TensorSpec(shape=(None, ), dtype=\"int64\"),\n",
    "    )\n",
    ")\n",
    "ds_y_batch = tf.data.Dataset.from_tensor_slices(tf.constant(example_graph_labels)).batch(batch_size)\n",
    "ds_batch = tf.data.Dataset.zip((ds_x_batch, ds_y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac726a2-9427-4b4b-a0ec-8d2a62e9f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 905ms/step - loss: 0.3999\n",
      "Epoch 2/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2608\n",
      "Epoch 3/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2581\n",
      "Epoch 4/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2573\n",
      "Epoch 5/7\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\anaconda3\\envs\\gcnn_keras_test\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2573\n",
      "Epoch 6/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2686\n",
      "Epoch 7/7\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2601fb2fe50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_passing_3.compile(loss=\"mean_absolute_error\")\n",
    "message_passing_3.fit(ds_batch, epochs=7, batch_size=None, steps_per_epoch=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be89df",
   "metadata": {},
   "source": [
    "> **NOTE**: You can find this page as jupyter notebook in https://github.com/aimat-lab/gcnn_keras/tree/master/docs/source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
