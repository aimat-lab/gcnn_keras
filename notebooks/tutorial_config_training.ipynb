{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras as ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameter dictionary used for model tuning, fitting and data structue has the following form:\n",
    "```python3\n",
    "hyper = {\n",
    "    \"info\":{ \n",
    "        # General information for training run\n",
    "        \"kgcnn_version\": \"2.0.0\", # Version \n",
    "        \"postfix\": \"\" # postfix for output folder\n",
    "    },\n",
    "    \"model\": { \n",
    "        # Model specific parameter, see kgcnn.literature\n",
    "    },\n",
    "    \"data\": { \n",
    "        # Dataset specific parameter\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"fit\": { \n",
    "            # keras fit arguments serialized\n",
    "        },\n",
    "        \"compile\": { \n",
    "            # Keras compile arguments serialized\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "The following sections explain each block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters can be reviewed from the default values in ``kgcnn.literature``. Mostly model input and output has to be matched depending on the data representation. That is type of input and its shape. An input-type checker can be used from `kgcnn.data.base.MemoryGraphDataset`, which has `assert_valid_model_input`. In ``inputs`` a list of kwargs must be given, which are each unpacked in the corresponding ``ks.layers.Input``. The order matters and is model dependent.\n",
    "\n",
    "Moreover, naming of the model input is used to link the tensor properties of the dataset with the model input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.update({\n",
    "    \"model\":{\n",
    "        \"module_name\": None, \n",
    "        \"class_name\": \"make_model\",\n",
    "        \"config\":{\n",
    "            \"inputs\": [\n",
    "                {\"shape\": [None, 100], \"name\": \"node_attributes\", \"dtype\": \"float32\"},\n",
    "                {\"shape\": [None, 2], \"name\": \"edge_indices\", \"dtype\": \"int64\"},\n",
    "                {\"shape\": (), \"name\": \"total_nodes\", \"dtype\": \"int64\"},\n",
    "                {\"shape\": (), \"name\": \"total_edges\", \"dtype\": \"int64\"}\n",
    "            ],\n",
    "            # More model specific kwargs, like:\n",
    "            \"depth\": 5,\n",
    "            # Output part defining model output\n",
    "            \"output_embedding\": \"graph\",\n",
    "            \"output_mlp\": {\"use_bias\": [True, True, False], \"units\": [140, 70, 70],\n",
    "                           \"activation\": [\"relu\", \"relu\", \"softmax\"]}\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training script should provide ``dataset.tensor({\"name\": \"edge_indices\"})`` of shape `(batch, None, 2)` and ``dataset.tensor({\"name\": \"node_attributes\"})`` of shape `(batch, None, 100)` from the dataset. Note that the shape must match the actual shape in dataset. Same for `total_nodes` and `total_edges`.\n",
    "\n",
    "For output, idally all models simply have a MLP at the output and the activation as well as the final output dimension can be chosen by setting the kwargs ``output_mlp`` (unpacked in MLP) for last layer in ``units`` and ``activation``. The number in units must macht the labels or classes of the target. This is mostly ``dataset.tensor({\"name\": \"graph_labels\"})``, but depends on dataset and classification task, either graph or node classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kwargs for the dataset are not fully identical and vary a little depending on the datset. However, the most common are listed below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.update({\n",
    "    \"data\":{      \n",
    "        # Other optinal entries (depends on the training script)\n",
    "        \"data_unit\": \"mol/L\",\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class_name\": \"QM9Dataset\", # Name of the dataset\n",
    "        \"module_name\": \"kgcnn.data.datasets.QM9Dataset\",\n",
    "        \n",
    "        # Config like filepath etc., leave empty for pre-defined datasets\n",
    "        \"config\": {}, \n",
    "        \n",
    "        # Methods to run on dataset, i.e. the list of graphs\n",
    "        \"methods\": [\n",
    "            {\"prepare_data\": {}}, # Used for cache and pre-compute data, leave out for pre-defined datasets\n",
    "            {\"read_in_memory\": {}}, # Used for reading into memory, leave out for pre-defined datasets\n",
    "            \n",
    "            # Example method to run over each graph in the list using `map_list` method.\n",
    "            {\"map_list\": {\"method\": \"set_range\", \"max_distance\": 4, \"max_neighbours\": 30}},\n",
    "            {\"map_list\": {\"method\": \"count_nodes_and_edges\", \"total_edges\": \"total_edges\",\n",
    "                          \"count_edges\": \"edge_indices\", \"count_nodes\": \"node_attributes\", \"total_nodes\": \"total_nodes\"}},\n",
    "        ]\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kwargs for training simply sets arguments for ``model.compile(**kwargs)`` and ``model.fit(**kwargs)`` that matches keras arguments as well as for the k-fold split from scikit-learn. The kwargs are expected to be fully serialized, if the hyper parameters are supposed to be saved to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.update({\n",
    "    \"training\":{\n",
    "        # Cross-validation of the data\n",
    "        \"cross_validation\": {\n",
    "            \"class_name\": \"KFold\",\n",
    "            \"config\": {\"n_splits\": 5, \"random_state\": 42, \"shuffle\": True}\n",
    "        },\n",
    "        # Standard scaler for regression targets\n",
    "        \"scaler\": {\n",
    "            \"class_name\": \"StandardScaler\",\n",
    "            \"module_name\": \"kgcnn.data.transform.scaler.standard\",\n",
    "            \"config\": {\"with_std\": True, \"with_mean\": True, \"copy\": True}\n",
    "        },\n",
    "        # Keras model compile and fit\n",
    "        \"compile\": {\n",
    "            \"loss\": \"categorical_crossentropy\",\n",
    "            \"optimizer\": ks.saving.serialize_keras_object(\n",
    "                ks.optimizers.Adam(learning_rate=0.001))\n",
    "        },\n",
    "        \"fit\": {\n",
    "            \"batch_size\": 32, \"epochs\": 800, \"verbose\": 2, \n",
    "            \"callbacks\": []\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general information on the training, such as the used kgcnn version or a postfix for the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.update({\n",
    "    \"info\":{ # Generla information\n",
    "        \"postfix\": \"_v1\", # Appends _v1 to output folder\n",
    "        \"postfix_file\": \"_run2\", # Appends _run2 to info files\n",
    "        \"kgcnn_version\": \"4.0.0\"    \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final hyper dictionary which can be fed to training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'module_name': None,\n",
       "  'class_name': 'make_model',\n",
       "  'config': {'inputs': [{'shape': [None, 100],\n",
       "     'name': 'node_attributes',\n",
       "     'dtype': 'float32'},\n",
       "    {'shape': [None, 2], 'name': 'edge_indices', 'dtype': 'int64'},\n",
       "    {'shape': (), 'name': 'total_nodes', 'dtype': 'int64'},\n",
       "    {'shape': (), 'name': 'total_edges', 'dtype': 'int64'}],\n",
       "   'depth': 5,\n",
       "   'output_embedding': 'graph',\n",
       "   'output_mlp': {'use_bias': [True, True, False],\n",
       "    'units': [140, 70, 70],\n",
       "    'activation': ['relu', 'relu', 'softmax']}}},\n",
       " 'data': {'data_unit': 'mol/L'},\n",
       " 'dataset': {'class_name': 'QM9Dataset',\n",
       "  'module_name': 'kgcnn.data.datasets.QM9Dataset',\n",
       "  'config': {},\n",
       "  'methods': [{'prepare_data': {}},\n",
       "   {'read_in_memory': {}},\n",
       "   {'map_list': {'method': 'set_range',\n",
       "     'max_distance': 4,\n",
       "     'max_neighbours': 30}},\n",
       "   {'map_list': {'method': 'count_nodes_and_edges',\n",
       "     'total_edges': 'total_edges',\n",
       "     'count_edges': 'edge_indices',\n",
       "     'count_nodes': 'node_attributes',\n",
       "     'total_nodes': 'total_nodes'}}]},\n",
       " 'training': {'cross_validation': {'class_name': 'KFold',\n",
       "   'config': {'n_splits': 5, 'random_state': 42, 'shuffle': True}},\n",
       "  'scaler': {'class_name': 'StandardScaler',\n",
       "   'module_name': 'kgcnn.data.transform.scaler.standard',\n",
       "   'config': {'with_std': True, 'with_mean': True, 'copy': True}},\n",
       "  'compile': {'loss': 'categorical_crossentropy',\n",
       "   'optimizer': {'module': 'keras.src.backend.torch.optimizers.torch_adam',\n",
       "    'class_name': 'Adam',\n",
       "    'config': {'name': 'adam',\n",
       "     'learning_rate': 0.0010000000474974513,\n",
       "     'weight_decay': None,\n",
       "     'clipnorm': None,\n",
       "     'global_clipnorm': None,\n",
       "     'clipvalue': None,\n",
       "     'use_ema': False,\n",
       "     'ema_momentum': 0.99,\n",
       "     'ema_overwrite_frequency': None,\n",
       "     'loss_scale_factor': None,\n",
       "     'beta_1': 0.9,\n",
       "     'beta_2': 0.999,\n",
       "     'epsilon': 1e-07,\n",
       "     'amsgrad': False},\n",
       "    'registered_name': 'Adam'}},\n",
       "  'fit': {'batch_size': 32, 'epochs': 800, 'verbose': 2, 'callbacks': []}},\n",
       " 'info': {'postfix': '_v1', 'postfix_file': '_run2', 'kgcnn_version': '4.0.0'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
